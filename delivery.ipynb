{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflexions sur le débruitage\n",
    "\n",
    "## SOMMAIRE\n",
    "\n",
    "#### I. Types de bruit\n",
    "\n",
    "* Bruit Gaussien\n",
    "* Bruit de Poisson\n",
    "* Bruit impulsionnel\n",
    "* Bruit uniforme\n",
    "\n",
    "#### II. Techniques de débruitage\n",
    "\n",
    "* **A. Filtres**\n",
    "  * Filtre moyen\n",
    "  * Filtre médian\n",
    "  * Filtre gaussien\n",
    "\n",
    "* **B. Statistiques**\n",
    "  * PCA\n",
    "    * Version de `sklearn`\n",
    "    * _Ma version_\n",
    "  * Non Local Means\n",
    "    * Version de `opencv`\n",
    "    * _Ma version_\n",
    "\n",
    "* **C. Réseaux de neurones**\n",
    "  * Auto encodeurs\n",
    "  * CNNs\n",
    "\n",
    "* **D. Débruiter des images plus complexes (EXR, 32 Bits Float...)**\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Le débruitage d'images est une technique utilisée en traitement d'images pour réduire ou éliminer le bruit présent dans une image. Le bruit est une perturbation indésirable généralement introduite lors de l'acquisition de l'image par des capteurs électroniques.\n",
    "\n",
    "Le débruitage d'images est crucial dans de nombreux domaines tels que :\n",
    "\n",
    "* **Imagerie médicale** : Pour améliorer la clarté des images obtenues par radiographie, IRM, etc.\n",
    "* **Photographie numérique** : Pour améliorer la qualité des photos prises dans des conditions de faible luminosité.\n",
    "* **Surveillance et sécurité** : Pour améliorer les images des caméras de surveillance.\n",
    "* **Astronomie** : Pour éliminer le bruit des images capturées par des télescopes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Types de Bruit\n",
    "\n",
    "#### Bruit Gaussien\n",
    "\n",
    "Bruit aléatoire suivant une distribution normale, souvent dû à des perturbations thermiques dans les capteurs.\n",
    "\n",
    "#### Bruit de Poisson\n",
    "\n",
    "Bruit dépendant de l'intensité du signal, typique dans les images acquises avec peu de lumière.\n",
    "\n",
    "#### Bruit Impulsionnel (Sel et Poivre)\n",
    "\n",
    "Apparition de pixels noirs et blancs aléatoirement répartis, souvent causé par des erreurs de transmission.\n",
    "\n",
    "#### Bruit Uniforme\n",
    "\n",
    "Bruit avec une distribution de probabilité uniforme sur une plage spécifique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.ndimage import gaussian_filter, median_filter\n",
    "import plotly.express as px\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage import img_as_float\n",
    "import matplotlib.pyplot as plt\n",
    "import OpenEXR\n",
    "import Imath\n",
    "import scipy.ndimage\n",
    "import cv2\n",
    "from skimage.restoration import denoise_nl_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Techniques de Débruitage\n",
    "\n",
    "Les méthodes de débruitage peuvent être classées en plusieurs catégories principales :\n",
    "\n",
    "#### A. Filtres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv(\"src/noisy_images.csv\")\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-176.321245</td>\n",
       "      <td>-52.743850</td>\n",
       "      <td>143.604939</td>\n",
       "      <td>-53.567749</td>\n",
       "      <td>80.289381</td>\n",
       "      <td>20.686379</td>\n",
       "      <td>-197.423519</td>\n",
       "      <td>-229.401206</td>\n",
       "      <td>-221.900009</td>\n",
       "      <td>64.194187</td>\n",
       "      <td>...</td>\n",
       "      <td>34.407070</td>\n",
       "      <td>1.950735</td>\n",
       "      <td>-25.095565</td>\n",
       "      <td>133.684095</td>\n",
       "      <td>-21.664094</td>\n",
       "      <td>-94.305438</td>\n",
       "      <td>-55.987821</td>\n",
       "      <td>-89.929231</td>\n",
       "      <td>40.394774</td>\n",
       "      <td>-214.754480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-158.421239</td>\n",
       "      <td>16.371695</td>\n",
       "      <td>62.810879</td>\n",
       "      <td>263.533916</td>\n",
       "      <td>-193.920320</td>\n",
       "      <td>-25.366668</td>\n",
       "      <td>107.062706</td>\n",
       "      <td>125.403427</td>\n",
       "      <td>83.536343</td>\n",
       "      <td>-55.713640</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.419961</td>\n",
       "      <td>-123.584030</td>\n",
       "      <td>20.240434</td>\n",
       "      <td>-25.699206</td>\n",
       "      <td>-128.545930</td>\n",
       "      <td>52.525885</td>\n",
       "      <td>-54.214887</td>\n",
       "      <td>-133.842624</td>\n",
       "      <td>-30.141215</td>\n",
       "      <td>210.408665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-290.343750</td>\n",
       "      <td>81.586500</td>\n",
       "      <td>12.615232</td>\n",
       "      <td>146.567851</td>\n",
       "      <td>111.233602</td>\n",
       "      <td>-188.989259</td>\n",
       "      <td>-101.464605</td>\n",
       "      <td>-107.015195</td>\n",
       "      <td>-13.069827</td>\n",
       "      <td>-245.921093</td>\n",
       "      <td>...</td>\n",
       "      <td>-139.909318</td>\n",
       "      <td>-85.214133</td>\n",
       "      <td>167.495617</td>\n",
       "      <td>62.402411</td>\n",
       "      <td>-144.402970</td>\n",
       "      <td>152.263950</td>\n",
       "      <td>-4.687051</td>\n",
       "      <td>-59.270131</td>\n",
       "      <td>-93.193600</td>\n",
       "      <td>188.229794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-208.840590</td>\n",
       "      <td>136.190431</td>\n",
       "      <td>38.552191</td>\n",
       "      <td>-67.825346</td>\n",
       "      <td>24.316303</td>\n",
       "      <td>176.103673</td>\n",
       "      <td>31.581298</td>\n",
       "      <td>-163.582673</td>\n",
       "      <td>29.777077</td>\n",
       "      <td>-110.969396</td>\n",
       "      <td>...</td>\n",
       "      <td>-131.385192</td>\n",
       "      <td>40.329733</td>\n",
       "      <td>-10.111639</td>\n",
       "      <td>163.497435</td>\n",
       "      <td>41.010287</td>\n",
       "      <td>-21.408008</td>\n",
       "      <td>328.274235</td>\n",
       "      <td>-15.341672</td>\n",
       "      <td>121.570863</td>\n",
       "      <td>151.757537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-328.876288</td>\n",
       "      <td>-42.862900</td>\n",
       "      <td>174.651874</td>\n",
       "      <td>-228.833439</td>\n",
       "      <td>71.909654</td>\n",
       "      <td>-97.206392</td>\n",
       "      <td>48.048853</td>\n",
       "      <td>-34.071313</td>\n",
       "      <td>3.820465</td>\n",
       "      <td>137.807730</td>\n",
       "      <td>...</td>\n",
       "      <td>-135.713199</td>\n",
       "      <td>-71.396796</td>\n",
       "      <td>155.237981</td>\n",
       "      <td>-141.860908</td>\n",
       "      <td>155.657335</td>\n",
       "      <td>166.609760</td>\n",
       "      <td>-52.911774</td>\n",
       "      <td>267.150703</td>\n",
       "      <td>-36.749672</td>\n",
       "      <td>131.913772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0      pixel1      pixel2      pixel3      pixel4      pixel5  \\\n",
       "0 -176.321245  -52.743850  143.604939  -53.567749   80.289381   20.686379   \n",
       "1 -158.421239   16.371695   62.810879  263.533916 -193.920320  -25.366668   \n",
       "2 -290.343750   81.586500   12.615232  146.567851  111.233602 -188.989259   \n",
       "3 -208.840590  136.190431   38.552191  -67.825346   24.316303  176.103673   \n",
       "4 -328.876288  -42.862900  174.651874 -228.833439   71.909654  -97.206392   \n",
       "\n",
       "       pixel6      pixel7      pixel8      pixel9  ...    pixel774  \\\n",
       "0 -197.423519 -229.401206 -221.900009   64.194187  ...   34.407070   \n",
       "1  107.062706  125.403427   83.536343  -55.713640  ...   -5.419961   \n",
       "2 -101.464605 -107.015195  -13.069827 -245.921093  ... -139.909318   \n",
       "3   31.581298 -163.582673   29.777077 -110.969396  ... -131.385192   \n",
       "4   48.048853  -34.071313    3.820465  137.807730  ... -135.713199   \n",
       "\n",
       "     pixel775    pixel776    pixel777    pixel778    pixel779    pixel780  \\\n",
       "0    1.950735  -25.095565  133.684095  -21.664094  -94.305438  -55.987821   \n",
       "1 -123.584030   20.240434  -25.699206 -128.545930   52.525885  -54.214887   \n",
       "2  -85.214133  167.495617   62.402411 -144.402970  152.263950   -4.687051   \n",
       "3   40.329733  -10.111639  163.497435   41.010287  -21.408008  328.274235   \n",
       "4  -71.396796  155.237981 -141.860908  155.657335  166.609760  -52.911774   \n",
       "\n",
       "     pixel781    pixel782    pixel783  \n",
       "0  -89.929231   40.394774 -214.754480  \n",
       "1 -133.842624  -30.141215  210.408665  \n",
       "2  -59.270131  -93.193600  188.229794  \n",
       "3  -15.341672  121.570863  151.757537  \n",
       "4  267.150703  -36.749672  131.913772  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filters(images, side_length: int, sigma: int = None, size: int = None):\n",
    "    rows = []\n",
    "    for image in images:\n",
    "        image = image.reshape(side_length, side_length)\n",
    "        if size:\n",
    "            image = median_filter(image, size=size)\n",
    "        if sigma:\n",
    "            image = gaussian_filter(image, sigma=sigma)\n",
    "        rows.append(image.flatten())\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtre Moyen\n",
    "\n",
    "Chaque pixel est remplacé par la moyenne des pixels de son voisinage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtre Median\n",
    "\n",
    "Chaque pixel est remplacé par la médiane des pixels de son voisinage, efficace contre le bruit impulsionnel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\".\"](https://raw.githubusercontent.com/tristanGIANDO/gt_denoiser/main/output/images/median_low.png)\n",
    "![\".\"](https://raw.githubusercontent.com/tristanGIANDO/gt_denoiser/main/output/images/median_high.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtre Gaussien\n",
    "\n",
    "Utilise une convolution avec une fonction gaussienne, réduisant le bruit gaussien de manière plus lisse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\".\"](https://raw.githubusercontent.com/tristanGIANDO/gt_denoiser/main/output/images/gaussian_low.png)\n",
    "![\".\"](https://raw.githubusercontent.com/tristanGIANDO/gt_denoiser/main/output/images/gaussian_high.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Statistiques\n",
    "\n",
    "##### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPCA:\n",
    "    def __init__(self, n_components: int = None) -> None:\n",
    "        self._components = n_components\n",
    "\n",
    "    def normalize_x(self, X):\n",
    "        mean = np.mean(X, axis=0)\n",
    "        std_dev = np.std(X, axis=0)\n",
    "\n",
    "        X = (X - mean) / std_dev\n",
    "\n",
    "        return X, mean, std_dev\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        if self._components is None:\n",
    "            self._components = X.shape[1]\n",
    "\n",
    "        # 1. Normalize X\n",
    "        X, self._X_mean, self._X_std_dev = self.normalize_x(X)\n",
    "\n",
    "        # 2. Calculate covariance matrix\n",
    "        cov_matrix = np.cov(X, rowvar=False)\n",
    "\n",
    "        # 3. Calculate eigen-vectors and eigen-values\n",
    "        self._eig_vals, self._eig_vecs = np.linalg.eig(cov_matrix)\n",
    "\n",
    "        # 4. Deduct PCA\n",
    "        indices = np.argsort(self._eig_vals)[::-1]\n",
    "\n",
    "        sort_eig_vecs = self._eig_vecs[:, indices]\n",
    "        self._sort_eig_vals = self._eig_vals[indices]\n",
    "\n",
    "        self._sel_eig_vecs = sort_eig_vecs[:, :self._components]\n",
    "\n",
    "        return np.dot(X, self._sel_eig_vecs)\n",
    "\n",
    "    def explained_variance_ratio_(self):\n",
    "        return np.real(self._sort_eig_vals / np.sum(self._sort_eig_vals))[:self._components]\n",
    "\n",
    "    def inverse_transform(self, X_pca):\n",
    "        dot_product = np.dot(X_pca, self._sel_eig_vecs.T)\n",
    "        return np.real((dot_product * self._X_std_dev) + self._X_mean)  # avoid complex issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(images: pd.DataFrame,\n",
    "            pca_components: float = None,\n",
    "            gaussian_strength: int = None,\n",
    "            median_strength: int = None):\n",
    "\n",
    "    side_length = int(np.sqrt(images.shape[1]))\n",
    "\n",
    "    my_pca = MyPCA(n_components=pca_components)\n",
    "    images = my_pca.fit_transform(images.values)\n",
    "    images = my_pca.inverse_transform(images)\n",
    "\n",
    "    images = apply_filters(images,\n",
    "                           side_length,\n",
    "                           sigma=gaussian_strength,\n",
    "                           size=median_strength)\n",
    "\n",
    "    return pd.DataFrame(images), my_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKLearn PCA :\n",
    "![\"skpca\"](https://raw.githubusercontent.com/tristanGIANDO/gt_denoiser/main/output/images/PCA_sklearn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual PCA\n",
    "![\"mypca\"](https://raw.githubusercontent.com/tristanGIANDO/gt_denoiser/main/output/images/PCA_custom.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Manual PCA -> {pca.explained_variance_ratio_().sum()} in {period} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **SKLearn PCA :** 84.999 % in 0.119 seconds\n",
    "* **My version of PCA :** -> 84.0344 % in 0.839 seconds\n",
    "\n",
    "##### Testing on \"lena_bruit.png\" (RGB, 512*512px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split image\n",
    "\n",
    "def split_into_blocks(channel, block_size=70):\n",
    "    h, w = channel.shape\n",
    "    # Ensure the dimensions are multiples of block_size\n",
    "    h_new = (h // block_size) * block_size\n",
    "    w_new = (w // block_size) * block_size\n",
    "    channel = channel[:h_new, :w_new]\n",
    "    \n",
    "    blocks = (channel.reshape(h_new // block_size, block_size, -1, block_size)\n",
    "              .swapaxes(1, 2)\n",
    "              .reshape(-1, block_size, block_size))\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def blocks_to_dataframe(blocks):\n",
    "    num_blocks = blocks.shape[0]\n",
    "    df = pd.DataFrame(blocks.reshape(num_blocks, -1))\n",
    "    return df\n",
    "\n",
    "\n",
    "# Load the image\n",
    "image_path = \"src/lena_bruit.png\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "image_np = np.array(image)\n",
    "\n",
    "# Separate the color channels\n",
    "red_channel = image_np[:, :, 0]\n",
    "green_channel = image_np[:, :, 1]\n",
    "blue_channel = image_np[:, :, 2]\n",
    "\n",
    "red_blocks = split_into_blocks(red_channel)\n",
    "green_blocks = split_into_blocks(green_channel)\n",
    "blue_blocks = split_into_blocks(blue_channel)\n",
    "\n",
    "blocks_to_dataframe(red_blocks).to_csv(\"src/R.csv\", index=False)\n",
    "blocks_to_dataframe(green_blocks).to_csv(\"src/G.csv\", index=False)\n",
    "blocks_to_dataframe(blue_blocks).to_csv(\"src/B.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoise image\n",
    "\n",
    "X = pd.read_csv(\"src/R.csv\")\n",
    "Y = pd.read_csv(\"src/G.csv\")\n",
    "Z = pd.read_csv(\"src/B.csv\")\n",
    "\n",
    "for layer, df in zip((\"R\", \"G\", \"B\"), (X, Y, Z)):\n",
    "    result, pca = denoise(df, pca_components=50, gaussian_strength=.6, median_strength=3)\n",
    "    result.to_csv(f\"output/denoised_{layer}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct image\n",
    "\n",
    "def reconstruct_image_from_blocks(df, h_blocks, w_blocks, block_size=5):\n",
    "    blocks = df.values.reshape((h_blocks, w_blocks, block_size, block_size))\n",
    "    blocks = blocks.swapaxes(1, 2).reshape(h_blocks * block_size, w_blocks * block_size)\n",
    "    return blocks\n",
    "\n",
    "\n",
    "df_red = pd.read_csv(\"output/denoised_R.csv\")\n",
    "df_green = pd.read_csv(\"output/denoised_G.csv\")\n",
    "df_blue = pd.read_csv(\"output/denoised_B.csv\")\n",
    "\n",
    "block_size = 70\n",
    "h_blocks = int(np.sqrt(len(df_red)))\n",
    "w_blocks = h_blocks\n",
    "\n",
    "red_channel_reconstructed = reconstruct_image_from_blocks(df_red, h_blocks, w_blocks, block_size)\n",
    "green_channel_reconstructed = reconstruct_image_from_blocks(df_green, h_blocks, w_blocks, block_size)\n",
    "blue_channel_reconstructed = reconstruct_image_from_blocks(df_blue, h_blocks, w_blocks, block_size)\n",
    "\n",
    "reconstructed_image_np = np.stack((red_channel_reconstructed, green_channel_reconstructed, blue_channel_reconstructed), axis=-1)\n",
    "reconstructed_image = Image.fromarray(reconstructed_image_np.astype('uint8'))\n",
    "\n",
    "\n",
    "reconstructed_image.save(\"output/lena_bruit_pca_100_gauss_06_median_3_size_70.png\")\n",
    "reconstructed_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this :\n",
    "\n",
    "![\".\"](https://raw.githubusercontent.com/tristanGIANDO/gt_denoiser/main/src/base_lena_bruit.png)\n",
    "\n",
    "\n",
    "To this (my favourites are the green ones):\n",
    "![\".\"](https://raw.githubusercontent.com/tristanGIANDO/gt_denoiser/main/output/images/patch_denoise_pca_median_gauss.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non Local Means\n",
    "\n",
    "Moyennage des pixels ayant des patchs similaires dans l'image, prenant en compte des pixels éloignés pour un meilleur lissage.\n",
    "I was a little frustrated.\n",
    "Despite the rather promising results, the quality of RGB denoising isn't really up to scratch with what we tested.\n",
    "\n",
    "So I went looking for the best known software methods and discovered the **non-local means** method.\n",
    "\n",
    "1. For each pixel, the NLM compares it with other pixels in the image, more or less distant.\n",
    "2. A weight is then calculated based on the similarity between the patches centered around the target pixel and the comparison pixel. The more similar the patches, the higher the weight.\n",
    "3. The target pixel is then replaced by a weighted average of all comparison pixels, using the calculated weights. This means that similar pixels have more influence on the final pixel value.\n",
    "\n",
    "**Result : Detail is preserved!**\n",
    "\n",
    "`open-cv` does this in one line and very quickly, but the aim of this project is to understand how it works. So I've redone my own version (which works even though it's _40 times_ slower!).\n",
    "\n",
    "###### NLM openCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(A, B):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(A)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f\"Result\")\n",
    "    plt.imshow(B)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"src/base_lena_bruit.png\")\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR to RGB\n",
    "\n",
    "image_denoised = cv2.fastNlMeansDenoisingColored(image_rgb, None, 25, 25, 7, 21)\n",
    "\n",
    "compare_results(image_rgb, image_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\".\"](https://raw.githubusercontent.com/tristanGIANDO/gt_denoiser/main/output/images/NLM_opencv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### NLM custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_NlMeansDenoisingColored(image: np.array,\n",
    "                                   patch_size: int = 3,\n",
    "                                   search_window_size: int = 21,\n",
    "                                   h: int = 10):\n",
    "    \"\"\"Denoise RGB image with non local means\n",
    "\n",
    "    Args:\n",
    "        image (np.array): RGB image\n",
    "        patch_size (int, optional): Size of sub-images to compare with others. Defaults to 3 -> matrix 3*3\n",
    "        search_window_size (int, optional): search area. Defaults to 21.\n",
    "        h (int, optional): intensity of the filter. Low = keep details, High = no details\n",
    "    \"\"\"\n",
    "    image = img_as_float(image)  # float pour des calculs plus precis\n",
    "\n",
    "    denoised = np.zeros_like(image)  # new image, same shape but only 0\n",
    "    \n",
    "    pad_size = search_window_size // 2  # fenetre de recherche\n",
    "    patch_radius = patch_size // 2\n",
    "    padded_image = np.pad(image,\n",
    "                          ((pad_size, pad_size),\n",
    "                           (pad_size, pad_size),\n",
    "                           (0, 0)),\n",
    "                           \"reflect\")\n",
    "    \n",
    "    # gauss\n",
    "    gaussian_kernel = np.exp(\n",
    "        -0.5\n",
    "        * (np.linspace(-patch_radius, patch_radius, patch_size) ** 2)\n",
    "        / (h ** 2))\n",
    "    gaussian_kernel = gaussian_kernel[:, None] * gaussian_kernel[None, :]\n",
    "    \n",
    "    # patches extraction\n",
    "    patches = np.lib.stride_tricks.as_strided(\n",
    "        padded_image,\n",
    "        shape=(padded_image.shape[0] - patch_size + 1,\n",
    "               padded_image.shape[1] - patch_size + 1,\n",
    "               patch_size,\n",
    "               patch_size,\n",
    "               image.shape[2]),\n",
    "        strides=padded_image.strides[:2] + padded_image.strides[:2] + padded_image.strides[2:]\n",
    "    )\n",
    "    \n",
    "    # original image, loop sur chaque pixel\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            # coords du pixel au centre des recherches\n",
    "            i1 = i + pad_size\n",
    "            j1 = j + pad_size\n",
    "            \n",
    "            # define search limits, borders\n",
    "            ref_patch = padded_image[i1-patch_radius:i1+patch_radius+1,\n",
    "                                     j1-patch_radius:j1+patch_radius+1, :]\n",
    "\n",
    "            i_min = max(i1 - pad_size, 0)\n",
    "            i_max = min(i1 + pad_size + 1, padded_image.shape[0] - patch_size + 1)\n",
    "            j_min = max(j1 - pad_size, 0)\n",
    "            j_max = min(j1 + pad_size + 1, padded_image.shape[1] - patch_size + 1)\n",
    "            \n",
    "            # patches extraction\n",
    "            search_window = patches[i_min:i_max, j_min:j_max]\n",
    "            search_window = search_window.reshape(-1,\n",
    "                                                  patch_size,\n",
    "                                                  patch_size,\n",
    "                                                  image.shape[2])\n",
    "            \n",
    "            # distance between ref patch and patch\n",
    "            distances = np.sum(\n",
    "                (search_window - ref_patch[None, :, :, :]) ** 2\n",
    "                * gaussian_kernel[None, :, :, None],\n",
    "                axis=(1, 2, 3))\n",
    "            \n",
    "            # weight by distances\n",
    "            weights = np.exp(-distances / (h ** 2))\n",
    "            weights /= np.sum(weights)\n",
    "            \n",
    "            # result\n",
    "            denoised[i, j, :] = np.sum(weights[:, None] * search_window[:, patch_radius, patch_radius, :], axis=0)\n",
    "    \n",
    "    return denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"src/lena_bruit.png\")\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "image_denoised = custom_NlMeansDenoisingColored(image_rgb, patch_size=5, search_window_size=15, h=1)\n",
    "\n",
    "compare_results(image_rgb, image_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\".\"](https://raw.githubusercontent.com/tristanGIANDO/gt_denoiser/main/output/images/NLM_custom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Réseaux de neurones\n",
    "\n",
    "##### Autoencodeurs\n",
    "\n",
    "Réseaux de neurones entraînés pour encoder puis décoder une image, apprenant à éliminer le bruit lors de la reconstruction.\n",
    "\n",
    "##### CNNs (Convolutional Neural Networks)\n",
    "\n",
    "Réseaux convolutifs spécialement conçus pour le débruitage d'images, exploitant des architectures profondes pour améliorer la qualité de l'image débruitée.\n",
    "\n",
    "#### D. Débruiter des images plus complexes (EXR, 32 bits Float...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_exr(file_path):\n",
    "    exr_file = OpenEXR.InputFile(file_path)\n",
    "    header = exr_file.header()\n",
    "    dw = header['dataWindow']\n",
    "    size = (dw.max.x - dw.min.x + 1, dw.max.y - dw.min.y + 1)\n",
    "\n",
    "    channels = {}\n",
    "    for channel_name in exr_file.header()['channels'].keys():\n",
    "        channel_data = exr_file.channel(channel_name, Imath.PixelType(Imath.PixelType.FLOAT))\n",
    "        channel = np.frombuffer(channel_data, dtype=np.float32).reshape(size[1], size[0])\n",
    "        channels[channel_name] = channel\n",
    "    \n",
    "    return channels, size\n",
    "\n",
    "def write_exr(file_path, channels, size):\n",
    "    header = OpenEXR.Header(size[0], size[1])\n",
    "    for channel_name in channels.keys():\n",
    "        header['channels'][channel_name] = Imath.Channel(Imath.PixelType(Imath.PixelType.FLOAT))\n",
    "    \n",
    "    exr_file = OpenEXR.OutputFile(file_path, header)\n",
    "    channel_data = {name: data.tobytes() for name, data in channels.items()}\n",
    "    exr_file.writePixels(channel_data)\n",
    "\n",
    "patch_kw = dict(patch_size=5, patch_distance=6, channel_axis=-1)  # 5x5 patches  # 13x13 search area\n",
    "def denoise_image(channels):\n",
    "    denoised_channels = {}\n",
    "    for channel_name, channel in channels.items():\n",
    "        denoised_channel = scipy.ndimage.median_filter(channel, size=12)\n",
    "        denoised_channel = scipy.ndimage.gaussian_filter(channel, sigma=1)\n",
    "        denoised_channels[channel_name] = denoised_channel\n",
    "    return denoised_channels\n",
    "\n",
    "def main(input_file, output_file):\n",
    "    channels, size = read_exr(input_file)\n",
    "    denoised_channels = denoise_image(channels)\n",
    "    write_exr(output_file, denoised_channels, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\".\"](https://raw.githubusercontent.com/tristanGIANDO/gt_denoiser/main/src/base_rafale.jpg)\n",
    "\n",
    "![\".\"](https://raw.githubusercontent.com/tristanGIANDO/gt_denoiser/main/output/images/rafale.jpg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
